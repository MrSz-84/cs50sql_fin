{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import config.config as cf\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = '../data/tv/tv_live_1.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {'NEONET.PL': 'NEONET AGD RTV',\n",
    "         'EURO.COM.PL': 'EURO RTV AGD',}\n",
    "dayparts = {'Off stacji': 'off',\n",
    "            'Prime stacji': 'prime'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def iter_over_inputs(data_set:list[dict[list,str,str,str]], con: sqlite3.Connection, \n",
    "                        cur: sqlite3.Cursor)-> None:\n",
    "    \"\"\"\n",
    "    Main loop for iteration over one column tables.\n",
    "\n",
    "    :param data_set: List containing dicts with data, table name and field/column name.\n",
    "    List contains strings or integers representing the data to be added into selected tables.\n",
    "    :param table_name: String representing name of the table into which data is going to be added\n",
    "    :param con: Is a connection object, pointing to a DB\n",
    "    :param cur: Is a cursor object created for con object\n",
    "    :raise KeyError: If key name does not match the pattern\n",
    "    :raise sqlite3.ProgrammingError: If there are any error raised by the DB-API\n",
    "    :raise sqlite3.OperationalError: If any exceptions on the DB side are raised, i.g. DB being locked\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    for elem in data_set:\n",
    "        data = elem['data']\n",
    "        table = elem['table']\n",
    "        field = elem['field']\n",
    "        table_type = elem['type']\n",
    "        data_type = elem['dtype']\n",
    "        new_data, data = check_for_data_1_field(data, table, field, data_type, cur)\n",
    "        if new_data:\n",
    "            add_1_field(data, table, field, table_type, data_type, con, cur)\n",
    "\n",
    "def add_1_field(data:list, table_name:str, field_name:str, type_:str, dtype:str,\n",
    "                con: sqlite3.Connection, cur: sqlite3.Cursor)-> None:\n",
    "    \"\"\"\n",
    "    Skeleton function for adding data to up to three column tables.\n",
    "\n",
    "    :param data: List of strings or integers representing table contents\n",
    "    :param table_name: String representing name of the table into which data is going to be added\n",
    "    :param type_: String representing type of target where to add the data. Available table or view\n",
    "    :param dtype: String representing to what type data should be converted before upload\n",
    "    :param con: Is a connection object, pointing to a DB\n",
    "    :param cur: Is a cursor object created for con object\n",
    "    :raise sqlite3.ProgrammingError: If there are any error raised by the DB-API\n",
    "    :raise sqlite3.OperationalError: If any exceptions on the DB side are raised, i.g. DB being locked\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    if type_ == 'table':\n",
    "        query = (f'INSERT INTO {table_name} ({field_name}) VALUES(:name);')\n",
    "    else:\n",
    "        if table_name == 'brandy':\n",
    "            query = (f'INSERT INTO podziel_brandy_view ({field_name}) VALUES(:name);')\n",
    "        else:\n",
    "            query = (f'INSERT INTO podziel_kanaly_view ({field_name}) VALUES(:name);')\n",
    "    for elem in data:\n",
    "        if dtype.startswith('int'):\n",
    "            to_add = {'name': int(elem)}\n",
    "        else:\n",
    "            to_add = {'name': str(elem)}\n",
    "            \n",
    "        cur.execute(query, to_add)\n",
    "    con.commit()\n",
    "\n",
    "def check_for_data_1_field(data_:list|pd.DataFrame, table_name:str, field_name:str, dtype:str,\n",
    "                            cur: sqlite3.Cursor,)-> tuple[bool,list[str|int]]:\n",
    "    \"\"\"\n",
    "    Skeleton function for checking if there is data inside each of one column tables.\n",
    "    Ads data if there are any new entries, skips if no new data was found. \n",
    "    If DB is empty returns immediately.\n",
    "\n",
    "    :param data_: List containing data to be checked and added. Data is of str or int types.\n",
    "    :param table_name: String representing name of the table into which data is going to be added\n",
    "    :param field_name: String representing name of the field/ column name\n",
    "    :param dtype: String representing to what type data should be converted before upload\n",
    "    :param cur: Is a cursor object created for con object\n",
    "    :param avoid_adding: List of tablet which doesn't need to be updated\n",
    "    :raise sqlite3.ProgrammingError: If there is an error raised by the DB-API\n",
    "    :raise sqlite3.OperationalError: If any exceptions on the DB side are raised, i.g. DB being locked\n",
    "    :return: A tuple containing bool for logic purposes, and the data set to be added\n",
    "    :rtype: tuple[bool, list[str|int]]\n",
    "    \"\"\"\n",
    "    \n",
    "    if table_name != 'kody_rek':\n",
    "        query = (f\"SELECT {field_name} FROM {table_name};\")\n",
    "    else:\n",
    "        query = (f\"SELECT kod_rek FROM {table_name};\")\n",
    "    cur.execute(query)\n",
    "    \n",
    "    in_db = pd.DataFrame([elem[0] for elem in cur.fetchall()])\n",
    "    in_db.rename(columns={0: field_name}, inplace=True)\n",
    "    if table_name == 'kody_rek':\n",
    "        in_db = in_db.astype('int32') # new\n",
    "    else:\n",
    "        in_db = in_db.astype(dtype) # new\n",
    "    \n",
    "    if len(in_db) == 0 and table_name in ('kody_rek', 'brandy', 'kanaly'):\n",
    "        data_ = data_.iloc[:, -1]\n",
    "        return (True, data_)\n",
    "    elif len(in_db) == 0:\n",
    "        return (True, data_)\n",
    "\n",
    "    if table_name not in ('kody_rek', 'brandy', 'kanaly'):\n",
    "        data_ = pd.DataFrame(data_)\n",
    "        data_ = data_.rename(columns={0: field_name})\n",
    "        data_ = data_.astype({field_name: dtype})\n",
    "    else: # new\n",
    "        cols = data_.columns.to_list() # new\n",
    "        if table_name == 'kody_rek':\n",
    "            data_ = data_.astype({cols[0]: 'int32'})\n",
    "        else:\n",
    "            data_ = data_.astype({cols[0]: dtype}) # new\n",
    "        \n",
    "    # we check if df contains new data in comparison to DB\n",
    "    if table_name in ('kody_rek', 'brandy', 'kanaly'):\n",
    "        filtr = ~data_[cols[0]].isin(in_db[field_name])\n",
    "        new_data = data_[filtr].dropna()\n",
    "        new_data = new_data.rename({cols[-1]: field_name}, axis=1)\n",
    "        new_data = new_data[field_name]\n",
    "    else:\n",
    "        filtr = ~data_[field_name].isin(in_db[field_name])\n",
    "        new_data = data_[filtr].dropna()\n",
    "        new_data = new_data[field_name]\n",
    "        \n",
    "    new_data = list(new_data)\n",
    "    \n",
    "    \n",
    "    if len(new_data) != 0:\n",
    "        print(f'>>> Adding to {table_name}. New data found.')\n",
    "        return (True, new_data)\n",
    "    else:\n",
    "        print(f'>>> Not adding to {table_name}. No new data found.')\n",
    "        return (False, list(''))\n",
    "\n",
    "def get_column_names(table_name:str, \n",
    "                    cur: sqlite3.Cursor)-> list[str]:\n",
    "    \"\"\"\n",
    "    A function which returns the names of selected table from the DB.\n",
    "\n",
    "    :param table_name: Name of a table out of which colum names are extracted from\n",
    "    :param con: A database connection object\n",
    "    :param cur: A cursor database object\n",
    "    :raise sqlite3.ProgrammingError: If column names does not match DB contents\n",
    "    :raise sqlite3.OperationalError: If any exceptions on the DB side are raised, i.g. DB being locked\n",
    "    :return: List containing all the column names present in selected table. \n",
    "    :rtype: list[str]\n",
    "    \"\"\"\n",
    "    \n",
    "    query = (\"SELECT name FROM pragma_table_info(:table_name);\")\n",
    "    data = {'table_name': table_name}\n",
    "    cur.execute(query, data)\n",
    "    table_data = cur.fetchall()\n",
    "    temp = []\n",
    "    for elem in table_data[1:]:\n",
    "        temp.append(elem[0])\n",
    "    table_data = temp\n",
    "    \n",
    "    return table_data\n",
    "\n",
    "def add_16_fields(data_set:dict[pd.DataFrame,str,list[str]],\n",
    "                  con: sqlite3.Connection, cur: sqlite3.Cursor)-> None:\n",
    "    \"\"\"\n",
    "    Function adding data into ad_time_details table, which consists of 14 columns.\n",
    "\n",
    "    :param data_set: A dict contaning data to be added, table name, and field / column name.\n",
    "    Data is a Pandas DataFrame, table name and field name are both strings.\n",
    "    :param con: A database connection object\n",
    "    :param cur: A cursor database object\n",
    "    :raise KeyError: If key name does not match the pattern\n",
    "    :raise sqlite3.ProgrammingError: If column names don't fit into the table design\n",
    "    :raise sqlite3.OperationalError: If any exceptions on the DB side are raised, i.g. DB being locked\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    query = (f\"\"\"\n",
    "             INSERT INTO {data_set['table']} (\n",
    "                {data_set['fields'][0]},\n",
    "                {data_set['fields'][1]},\n",
    "                {data_set['fields'][2]},\n",
    "                {data_set['fields'][3]},\n",
    "                {data_set['fields'][4]},\n",
    "                {data_set['fields'][5]},\n",
    "                {data_set['fields'][6]},\n",
    "                {data_set['fields'][7]},\n",
    "                {data_set['fields'][8]},\n",
    "                {data_set['fields'][9]},\n",
    "                {data_set['fields'][10]},\n",
    "                {data_set['fields'][11]},\n",
    "                {data_set['fields'][12]},\n",
    "                {data_set['fields'][13]},\n",
    "                {data_set['fields'][14]},\n",
    "                {data_set['fields'][15]})\n",
    "             VALUES(\n",
    "                :{data_set['fields'][0]},\n",
    "                :{data_set['fields'][1]},\n",
    "                :{data_set['fields'][2]},\n",
    "                :{data_set['fields'][3]},\n",
    "                :{data_set['fields'][4]},\n",
    "                :{data_set['fields'][5]},\n",
    "                :{data_set['fields'][6]},\n",
    "                :{data_set['fields'][7]},\n",
    "                :{data_set['fields'][8]},\n",
    "                :{data_set['fields'][9]},\n",
    "                :{data_set['fields'][10]},\n",
    "                :{data_set['fields'][11]},\n",
    "                :{data_set['fields'][12]},\n",
    "                :{data_set['fields'][13]},\n",
    "                :{data_set['fields'][14]},\n",
    "                :{data_set['fields'][15]})\n",
    "             ;\"\"\")\n",
    "\n",
    "    for _, elem in data_set['data'].iterrows():\n",
    "        elem.Date = elem.Date.strftime('%Y-%m-%d')\n",
    "        data = {field: elem for field, elem in zip(data_set['fields'], elem)}\n",
    "        cur.execute(query, data)\n",
    "        \n",
    "    con.commit()\n",
    "    \n",
    "def get_id_for_spoty(fields: list[str], table_: str,\n",
    "                        cur: sqlite3.Cursor)-> tuple[bool,pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Gets IDs from reference tables to aspoty table. \n",
    "    Mainly connects other tables and data of singular ad emission via IDs with other tables.\n",
    "    This function populates one of two core tables in this DB.\n",
    "    Returns a bool for logic purposes and data to be added into mediums.\n",
    "\n",
    "    :param fields: A list containing field / column names represented as a str\n",
    "    :param table_: Name of the table out of which the data is going to be pulled, \n",
    "    represented as a str\n",
    "    :param cur: A cursor database object\n",
    "    :raise sqlite3.ProgrammingError: If column names don't fit into the table design\n",
    "    :raise sqlite3.OperationalError: If any exceptions on the DB side are raised, i.g. DB being locked\n",
    "    :return: Tuple containing bool for logic purposes and a Pandas DataFrame \n",
    "    as data to be added into the DB during the update or initial DB fill.\n",
    "    :rtype: tuple[bool, pd.DataFrame]\n",
    "    \"\"\"\n",
    "    \n",
    "    spoty = df_tv[['Date', 'Time', 'PIB pos', 'PIB count', 'PIB (real) rel', 'Spot Class', 'Block Code', 'Dayparts', 'GRP', \n",
    "                'Channel', 'Brand', 'Dur rounded,sp', 'Film Code/2', 'Prog Campaign', 'Prog Before', 'Prog After', 'Zlepek']]\n",
    "    spoty = spoty.astype({'Film Code/2':'int32'})\n",
    "    \n",
    "    query1 = (\"SELECT pib_real_rel, id FROM pib_real_rels;\")\n",
    "    cur.execute(query1)\n",
    "    pib_real_rel_id = dict(cur.fetchall())\n",
    "    query2 =(\"SELECT klasa_spotu, id FROM klasy_spotu;\")\n",
    "    cur.execute(query2)\n",
    "    klasa_spotu_id = dict(cur.fetchall())\n",
    "    query3 = (\"SELECT kod_bloku, id FROM kody_bloku;\")\n",
    "    cur.execute(query3)\n",
    "    kod_bloku_id = dict(cur.fetchall())\n",
    "    query4 = (\"SELECT daypart, id FROM dayparty;\")\n",
    "    cur.execute(query4)\n",
    "    daypart_id = dict(cur.fetchall())\n",
    "    query5 = (\"SELECT kanal, id FROM kanaly;\")\n",
    "    cur.execute(query5)\n",
    "    kanal_id = dict(cur.fetchall())\n",
    "    query6 = (\"SELECT brand, id FROM brandy;\")\n",
    "    cur.execute(query6)\n",
    "    brand_id = dict(cur.fetchall())\n",
    "    query7 = (\"SELECT kod_rek, id FROM kody_rek;\")\n",
    "    cur.execute(query7)\n",
    "    kod_rek_id = dict(cur.fetchall())\n",
    "    query8 = (\"SELECT prog_kampania, id FROM prog_kampanie;\")\n",
    "    cur.execute(query8)\n",
    "    prog_kampania_id = dict(cur.fetchall())\n",
    "    query9 = (\"SELECT dlugosc, id FROM dlugosci;\")\n",
    "    cur.execute(query9)\n",
    "    dlugosc = dict(cur.fetchall())\n",
    "    query10 = (\"SELECT program_przed, id FROM programy_przed;\")\n",
    "    cur.execute(query10)\n",
    "    program_przed_id = dict(cur.fetchall())\n",
    "    query11 = (\"SELECT program_po, id FROM programy_po;\")\n",
    "    cur.execute(query11)\n",
    "    program_po_id = dict(cur.fetchall())\n",
    "    \n",
    "    spoty.loc[:, 'PIB (real) rel'] = spoty['PIB (real) rel'].map(pib_real_rel_id)\n",
    "    spoty.loc[:, 'Spot Class'] = spoty['Spot Class'].map(klasa_spotu_id)\n",
    "    spoty.loc[:, 'Block Code'] = spoty['Block Code'].map(kod_bloku_id)\n",
    "    spoty.loc[:, 'Dayparts'] = spoty['Dayparts'].map(daypart_id)\n",
    "    spoty.loc[:, 'Channel'] = spoty['Channel'].map(kanal_id)\n",
    "    spoty.loc[:, 'Brand'] = spoty['Brand'].map(brand_id)\n",
    "    spoty.loc[:, 'Film Code/2'] = spoty['Film Code/2'].map(kod_rek_id).astype('int32')\n",
    "    spoty.loc[:, 'Prog Campaign'] = spoty['Prog Campaign'].map(prog_kampania_id)\n",
    "    spoty.loc[:, 'Dur rounded,sp'] = spoty['Dur rounded,sp'].map(dlugosc).astype('int8')\n",
    "    spoty.loc[:, 'Prog Before'] = spoty['Prog Before'].map(program_przed_id)\n",
    "    spoty.loc[:, 'Prog After'] = spoty['Prog After'].map(program_po_id)\n",
    "    \n",
    "    trigger, spoty = get_unique_record(fields, table_, spoty, cur)\n",
    "\n",
    "    return (trigger, spoty)\n",
    "\n",
    "def get_unique_record(fields: list[str], table_: str, dataframe: pd.DataFrame, \n",
    "                     cur: sqlite3.Cursor)-> tuple[bool, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Gets max and min dates from selected table. Then checks if dates present in the DF passed as a parameter\n",
    "    are outside of dates range. If so, allows data insertion into the DB, if not it informs the user, \n",
    "    and proceedes with the rest of the code.\n",
    "\n",
    "    :param fields: A list containing field / column names represented as a str\n",
    "    :param table_: Name of the table out of which the data is going to be pulled, \n",
    "    represented as a str\n",
    "    :param dataframe: Pandas DataFrame with the new data to be checked if not present in selected table\n",
    "    :param cur: A cursor database object\n",
    "    :raise sqlite3.ProgrammingError: If column names don't fit into the table design\n",
    "    :raise sqlite3.OperationalError: If any exceptions on the DB side are raised, i.g. DB being locked\n",
    "    :return: Tuple containing bool for logic purposes and a Pandas DataFrame \n",
    "    as data to be added into the DB during the update or initial DB fill.\n",
    "    :rtype: tuple[bool, pd.DataFrame]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get dates range from DB\n",
    "    query = (f\"\"\"\n",
    "                SELECT {fields[0]} || {fields[1]} || brand || kanal || kod_rek \n",
    "                FROM {table_}\n",
    "                JOIN kody_rek ON kody_rek.id = spoty.kod_rek_id\n",
    "                JOIN kanaly ON spoty.kanal_id = kanaly.id\n",
    "                JOIN brandy ON spoty.brand_id = brandy.id;\n",
    "            \"\"\")\n",
    "    cur.execute(query)\n",
    "    in_db = pd.DataFrame(cur.fetchall())\n",
    "    in_db.rename(columns={0: 'Zlepek'}, inplace=True)\n",
    "    \n",
    "    # # Filter out dates that are already in DB.\n",
    "    if not in_db.empty:\n",
    "        filtr = ~dataframe['Zlepek'].isin(in_db['Zlepek'])\n",
    "        dataframe = dataframe.loc[filtr]\n",
    "    \n",
    "    # Main logic add if empty or when dates not present in DB.\n",
    "    if in_db.empty:\n",
    "        return (True, dataframe)\n",
    "    elif dataframe.empty:\n",
    "        print(f'>>> Not adding to {table_}. One or more dates already in DB.')\n",
    "        print(f'>>> Check the data you want to insert into DB.')\n",
    "        return (False, dataframe)\n",
    "    else:\n",
    "        print(f'>>> Adding to {table_}. New data found.')\n",
    "        return (True, dataframe)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oppening connection.\n"
     ]
    }
   ],
   "source": [
    "# Opens connection to the DB\n",
    "print('Oppening connection.')\n",
    "con = sqlite3.Connection(cf.DB_PATH)\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tv = pd.read_csv(file_path, delimiter=';', thousands=' ', decimal=',', dtype={\n",
    "                    'Month': 'category', 'Week': 'category', 'Weekday': 'category',\n",
    "                    'Dayparts': 'object', 'Channel Groups': 'object', \n",
    "                    'Channel': 'object', 'PIB pos': 'int8', 'PIB (real) rel': 'object',\n",
    "                    'PIB count': 'int16', 'Dur rounded,sp': 'int8', 'Spot Class': 'object',\n",
    "                    'Block Code': 'object', 'Syndicate': 'object', 'Producer': 'object',\n",
    "                    'Brand': 'object', 'Film Code': 'object', 'Prog Campaign': 'object',\n",
    "                    'Prog Before': 'object', 'Prog After': 'object', \n",
    "                    'Film Code/2': 'object', 'TRP All 40+ cities 200- (i wsie) Nat[TSV2]': 'float64'}, \n",
    "                    parse_dates=['Date', 'Time'], date_format='%d.%m.%Y'\n",
    "                    )\n",
    "df_tv.rename(columns={'TRP All 40+ cities 200- (i wsie) Nat[TSV2]': 'GRP'}, inplace=True)\n",
    "df_tv['Brand'] = df_tv['Brand'].str.strip()\n",
    "df_tv['Brand'] = df_tv['Brand'].str.upper()\n",
    "df_tv['Producer'] = df_tv['Producer'].str.upper()\n",
    "df_tv['Syndicate'] = df_tv['Syndicate'].str.upper()\n",
    "df_tv['Brand'] = df_tv['Brand'].map(names).fillna(df_tv['Brand'])\n",
    "df_tv['Dayparts'] = df_tv['Dayparts'].map(dayparts).fillna(df_tv['Dayparts'])\n",
    "df_tv['DateTime'] = df_tv['Date'].astype('str') + ' ' + df_tv['Time']\n",
    "df_tv['Kod Opis'] = df_tv['Film Code/2'] + '@|@' + df_tv['Film Code']\n",
    "df_tv['Kanal Grupa'] = df_tv['Channel'] + '@|@' + df_tv['Channel Groups']\n",
    "df_tv['Brand Prod Synd'] = df_tv['Brand'] + '@|@' + df_tv['Producer'] + '#|#' + df_tv['Syndicate']\n",
    "df_tv['Zlepek'] = df_tv['Date'].dt.strftime('%Y-%m-%d') + df_tv['Time'] + df_tv['Brand'] + df_tv['Channel'] + df_tv['Film Code/2']\n",
    "# df_tv['DateTime'] = pd.to_datetime(df_tv['DateTime'], format='ISO8601')\n",
    "df_tv[['Dayparts', 'Prog Before', 'Prog After']] = df_tv[['Dayparts', 'Prog Before', 'Prog After']].fillna('brak danych', axis=1)\n",
    "df_tv.sort_values(by='Date', inplace=True, axis=0)\n",
    "df_tv.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "dates = df_tv['Date'].dt.strftime('%Y-%m-%d').unique()\n",
    "ad_codes = df_tv.loc[:, ['Film Code/2', 'Kod Opis']].drop_duplicates(subset=['Film Code/2'], keep='first', ignore_index=True)\n",
    "brands = df_tv.loc[:, ['Brand', 'Brand Prod Synd']].drop_duplicates(subset=['Brand'], keep='first', ignore_index=True)\n",
    "channels = df_tv.loc[:, ['Channel', 'Kanal Grupa']].drop_duplicates(subset=['Channel'], keep='first', ignore_index=True)\n",
    "dayparts = df_tv['Dayparts'].unique()\n",
    "pib_real_rels = df_tv['PIB (real) rel'].unique()\n",
    "durations = df_tv['Dur rounded,sp'].unique()\n",
    "spot_classes = df_tv['Spot Class'].unique()\n",
    "block_codes = df_tv['Block Code'].unique()\n",
    "prog_campaign = df_tv['Prog Campaign'].unique()\n",
    "prog_before= df_tv['Prog Before'].unique()\n",
    "prog_after = df_tv['Prog After'].unique()\n",
    "\n",
    "data_set = [{'data': dates, **cf.DATES},\n",
    "            {'data': dayparts, **cf.DAYPARTS},\n",
    "            {'data': pib_real_rels, **cf.PIB_R},\n",
    "            {'data': durations, **cf.DUR},\n",
    "            {'data': spot_classes, **cf.SPOT_CLASS},\n",
    "            {'data': block_codes, **cf.BLOCK_CODE},\n",
    "            {'data': prog_campaign, **cf.PR_CAMP},\n",
    "            {'data': prog_before, **cf.PR_BEF},\n",
    "            {'data': prog_after, **cf.PR_AFT},\n",
    "            {'data': ad_codes, **cf.AD_CODE},\n",
    "            {'data': brands, **cf.BRANDS},\n",
    "            {'data': channels, **cf.CHANNELS},\n",
    "            ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting data to one input tables.\n",
      ">>> Adding to data_czas. New data found.\n",
      ">>> Adding to dayparty. New data found.\n",
      ">>> Not adding to pib_real_rels. No new data found.\n",
      ">>> Adding to dlugosci. New data found.\n",
      ">>> Not adding to klasy_spotu. No new data found.\n",
      ">>> Not adding to kody_bloku. No new data found.\n",
      ">>> Adding to prog_kampanie. New data found.\n",
      ">>> Adding to programy_przed. New data found.\n",
      ">>> Adding to programy_po. New data found.\n",
      ">>> Adding to kody_rek. New data found.\n",
      ">>> Adding to brandy. New data found.\n",
      ">>> Adding to kanaly. New data found.\n",
      "Inserting data to the sixteen input table.\n",
      ">>> Adding to spoty. New data found.\n"
     ]
    }
   ],
   "source": [
    "print('Inserting data to one input tables.')\n",
    "try:\n",
    "    iter_over_inputs(data_set, con, cur)\n",
    "except sqlite3.ProgrammingError as e:\n",
    "    con.close()\n",
    "    print('Failed to input the data.')\n",
    "    print(f'Error: {e}')\n",
    "except sqlite3.OperationalError as e:\n",
    "    con.close()\n",
    "    print('Failed to input the data.')\n",
    "    print(f'Error: {e}')\n",
    "    exit()\n",
    "except sqlite3.IntegrityError as e:\n",
    "    con.close()\n",
    "    print('Failed to input the data.')\n",
    "    print(f'Error: {e}')\n",
    "    exit()\n",
    "\n",
    "\n",
    "print('Inserting data to the sixteen input table.')\n",
    "fields = get_column_names('spoty', cur)\n",
    "trigger, spoty = get_id_for_spoty(fields, 'spoty', cur)\n",
    "data_set2 = {'data': spoty, 'table': 'spoty', 'fields': fields}\n",
    "if trigger:\n",
    "    try:\n",
    "        add_16_fields(data_set2, con, cur)\n",
    "    except sqlite3.ProgrammingError as e:\n",
    "        con.close()\n",
    "        print('Failed to input the data.')\n",
    "        print(f'Error: {e}')\n",
    "        exit()\n",
    "    except sqlite3.OperationalError as e:\n",
    "        con.close()\n",
    "        print('Failed to input the data.')\n",
    "        print(f'Error: {e}')\n",
    "        exit()\n",
    "    except sqlite3.IntegrityError as e:\n",
    "        con.close()\n",
    "        print('Failed to input the data.')\n",
    "        print(f'Error: {e}')\n",
    "        exit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
