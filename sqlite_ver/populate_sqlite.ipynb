{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_index_val(table_name: str, cur: sqlite3.Cursor)-> int:\n",
    "    \"\"\"\n",
    "    Function gets max index value from the selected table and returns it as an integer increased by one.\n",
    "    When the table is empty, returns 1\n",
    "\n",
    "    :param table_name: Name of the table out of which the data is going to be pulled, \n",
    "    represented as a str\n",
    "    :param cur: Is a cursor object created for con object\n",
    "    :raise sqlite3.ProgrammingError: If there are any error raised by the DB-API\n",
    "    :daise sqlite3.OperationalError: If any eceptions on the DB side are raised, i.g. DB being locked\n",
    "    :return: number representiung max index value of selected table icreased by 1\n",
    "    :rtype: int\n",
    "    \"\"\"\n",
    "    \n",
    "    query = (f'SELECT MAX(id) FROM {table_name};')\n",
    "    cur.execute(query)\n",
    "    ind = cur.fetchone()\n",
    "    if ind[0] == None:\n",
    "        return 1\n",
    "    else:\n",
    "        return ind[0] + 1\n",
    "    \n",
    "def iter_over_inputs(data_set:list[dict[list,str,str]], con: sqlite3.Connection, \n",
    "                        cur: sqlite3.Cursor, avoid_adding: list[str])-> None:\n",
    "    \"\"\"\n",
    "    Main loop for iteration over one column tables.\n",
    "\n",
    "    :param data_set: List containing dicts with data, table name and field/column name.\n",
    "    List contains strings or integers representing the data to be added into selected tables.\n",
    "    :param table_name: String representing name of the table into which data is going to be added\n",
    "    :param con: Is a connection object, pointing to a DB\n",
    "    :param cur: Is a cursor object created for con object\n",
    "    :param avoid_adding: List of tablet which doesn't need to be updated\n",
    "    :raise KeyError: If key name does not match the pattern\n",
    "    :raise sqlite3.ProgrammingError: If there are any error raised by the DB-API\n",
    "    :daise sqlite3.OperationalError: If any eceptions on the DB side are raised, i.g. DB being locked\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    for elem in data_set:\n",
    "        data = elem['data']\n",
    "        table = elem['table']\n",
    "        field = elem['field']\n",
    "        new_data, data = check_for_data_1_field(data, table, field, cur, avoid_adding)\n",
    "        if new_data:\n",
    "            add_1_field(data, table, field, con, cur)\n",
    "\n",
    "def add_1_field(data:list, table_name:str, field_name: str, \n",
    "                con: sqlite3.Connection, cur: sqlite3.Cursor)-> None:\n",
    "    \"\"\"\n",
    "    Skeleton function for adding data to single column tables.\n",
    "\n",
    "    :param data: List of strings or integers representing table contents\n",
    "    :param table_name: String reprexsenting name of the table into which data is going to be added\n",
    "    :param con: Is a connection object, pointing to a DB\n",
    "    :param cur: Is a cursor object created for con object\n",
    "    :raise sqlite3.ProgrammingError: If there are any error raised by the DB-API\n",
    "    :daise sqlite3.OperationalError: If any eceptions on the DB side are raised, i.g. DB being locked\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    query = (f'INSERT INTO {table_name} ({field_name}) VALUES(:name);')\n",
    "    for elem in data:\n",
    "        to_add = {'name': str(elem)}\n",
    "        cur.execute(query, to_add)\n",
    "    con.commit()\n",
    "\n",
    "def check_for_data_1_field(data_:list, table_name:str, field_name:str, \n",
    "                            cur: sqlite3.Cursor, avoid_adding: list[str])-> tuple[bool,list[str]]:\n",
    "    \"\"\"\n",
    "    Skeleton function for checking if there is data inside each of one column tables.\n",
    "    Ads data if there are any new entries, skips if no new data was found. \n",
    "    If DB is empty returns immediately.\n",
    "\n",
    "    :param data_: List containing data to be checked and added. Data is of str or int types.\n",
    "    :param table_name: String representing name of the table into which data is going to be added\n",
    "    :param field_name: String representing name of the field/ column name\n",
    "    :param cur: Is a cursor object created for con object\n",
    "    :param avoid_adding: List of tablet which doesn't need to be updated\n",
    "    :raise sqlite3.ProgrammingError: If there is an error raised by the DB-API\n",
    "    :daise sqlite3.OperationalError: If any eceptions on the DB side are raised, i.g. DB being locked\n",
    "    :return: A tuple containing bool for logic purposes, anbd the data set to be added\n",
    "    :rtype: tuple[bool, list[str/int]]\n",
    "    \"\"\"\n",
    "    \n",
    "    query = (f'SELECT {field_name} FROM {table_name}')\n",
    "    cur.execute(query)\n",
    "    \n",
    "    in_db = pd.DataFrame([elem[0] for elem in cur.fetchall()])\n",
    "    in_db.rename(columns={0: field_name}, inplace=True)\n",
    "    \n",
    "    if len(in_db) == 0:\n",
    "        return (True, data_)\n",
    "    else:\n",
    "        if field_name == 'data':\n",
    "            # in_db['data'] = pd.to_datetime(in_db['data'])\n",
    "            in_db = list(in_db['data'])\n",
    "        else: \n",
    "            in_db = list(in_db[field_name])\n",
    "        \n",
    "        if len(in_db) != 0 and table_name in avoid_adding:\n",
    "            print(f'>>> Not adding to {table_name}. No new data found.')\n",
    "            return (False, list(''))\n",
    "        in_df = pd.DataFrame(data_)\n",
    "        in_df = in_df.rename(columns={0: field_name})\n",
    "        # if field_name == 'data':\n",
    "        #     pass\n",
    "            # in_df['data'] = pd.to_datetime(in_df['data'])\n",
    "        \n",
    "        # we check if df contains new data in comparison to DB\n",
    "        new_data = in_df[~in_df.isin(in_db)].dropna()\n",
    "        new_data = new_data[field_name]\n",
    "        new_data = list(new_data)\n",
    "        \n",
    "        if len(new_data) != 0:\n",
    "            print(f'>>> Adding to {table_name}. New data found.')\n",
    "            return (True, new_data)\n",
    "        else:\n",
    "            print(f'>>> Not adding to {table_name}. No new data found.')\n",
    "            return (False, list(''))\n",
    "        \n",
    "def add_3_fields(data_set:dict[pd.DataFrame,str,list], \n",
    "                 con: sqlite3.Connection, cur: sqlite3.Cursor)-> None:\n",
    "    \"\"\"\n",
    "    Function adding data into mediums table, which consists of 3 columns.\n",
    "\n",
    "    :param data_set: A dict contaning data to be added, table name, and field / column name.\n",
    "    Data is a Pandas DataFrame, table name and field name are both strings.\n",
    "    :raise KeyError: If key name does not match the pattern\n",
    "    :raise sqlite3.ProgrammingError: If table or field names doesn't match those in the DB\n",
    "    :daise sqlite3.OperationalError: If any eceptions on the DB side are raised, i.g. DB being locked\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    # col = data_set['data'].columns.values.tolist()\n",
    "    \n",
    "    query = (f\"\"\"\n",
    "             INSERT INTO {data_set['table']} \n",
    "             ({data_set['fields'][0]}, \n",
    "             {data_set['fields'][1]}, \n",
    "             {data_set['fields'][2]})\n",
    "             VALUES\n",
    "             (:{data_set['fields'][0]}, \n",
    "             :{data_set['fields'][1]}, \n",
    "             :{data_set['fields'][2]})\n",
    "             \"\"\")\n",
    "\n",
    "    for _, elem in data_set['data'].iterrows():\n",
    "        # TODO do type casting before data insertion\n",
    "        \n",
    "        data = {f'{field}': value for field, value in zip(data_set['fields'], elem)}\n",
    "        cur.execute(query, data)\n",
    "        \n",
    "    con.commit()\n",
    "\n",
    "def get_column_names(table_name:str, \n",
    "                    cur: sqlite3.Cursor)-> list[str]:\n",
    "    \"\"\"\n",
    "    A function which returns the names of selected table from the DB.\n",
    "\n",
    "    :param table_name: Name of a table out of which colum names are extracted from\n",
    "    :param con: A database connection object\n",
    "    :param cur: A cursor database object\n",
    "    :raise sqlite3.ProgrammingError: If column names does not match DB contents\n",
    "    :daise sqlite3.OperationalError: If any eceptions on the DB side are raised, i.g. DB being locked\n",
    "    :return: List containing all the column names present in selected table. \n",
    "    :rtype: list[str]\n",
    "    \"\"\"\n",
    "    \n",
    "    query = (\"SELECT name FROM pragma_table_info(:table_name);\")\n",
    "    data = {'table_name': table_name}\n",
    "    cur.execute(query, data)\n",
    "    table_data = cur.fetchall()\n",
    "    temp = []\n",
    "    for elem in table_data[1:]:\n",
    "        temp.append(elem[0])\n",
    "    table_data = temp\n",
    "    \n",
    "    return table_data\n",
    "\n",
    "def get_id_for_submediums(fields_:list[str], table_:str, \n",
    "                          cur: sqlite3.Cursor)-> tuple[bool, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Gets IDs from reference tables to mediums table. \n",
    "    Mainly connects submediums with broadcaster and reach tables.\n",
    "    Returns a bool for logic purposes and data to be added into mediums.\n",
    "\n",
    "    :param fields_: A list containing field / column names represented as a str\n",
    "    :param table_: Name of the table out of which the data is going to be pulled, \n",
    "    represented as a str\n",
    "    :param con: A database connection object\n",
    "    :param cur: A cursor database object\n",
    "    :raise sqlite3.ProgrammingError: If column names don't fit into the table design\n",
    "    :daise sqlite3.OperationalError: If any eceptions on the DB side are raised, i.g. DB being locked\n",
    "    :return: Tuple containing bool for logic purposes and a Pandas DataFrame \n",
    "    as data to be added into the DB during the update or initial DB fill.\n",
    "    :rtype: tuple[bool, pd.DataFrame]\n",
    "    \"\"\"\n",
    "    \n",
    "    submedia = df[['Submedium', 'Wydawca/Nadawca', 'Zasięg medium']].sort_values(by='Submedium')\n",
    "    submedia.drop_duplicates(subset=['Submedium'], keep='first', inplace=True, ignore_index=True)\n",
    "    \n",
    "    if sum(submedia.value_counts()) != submedia.index.max() + 1:\n",
    "        exit('Max index different than the length of the list.')\n",
    "    \n",
    "    query1 = (f\"SELECT nadawca, id FROM nadawcy;\")\n",
    "    cur.execute(query1)\n",
    "    nadawcy = dict(cur.fetchall())\n",
    "\n",
    "    query2 = (\"SELECT zasieg, id FROM zasiegi;\")\n",
    "    cur.execute(query2)\n",
    "    zasiegi = dict(cur.fetchall())\n",
    "\n",
    "    submedia['Wydawca/Nadawca'] = submedia['Wydawca/Nadawca'].map(nadawcy)\n",
    "    submedia['Zasięg medium'] = submedia['Zasięg medium'].map(zasiegi)\n",
    "    \n",
    "    trigger, submedia = check_for_data_3_fields(fields_, table_, submedia, cur)\n",
    "    \n",
    "    return (trigger, submedia)\n",
    "\n",
    "def check_for_data_3_fields(fields:list[str], table_name: str, submedia: pd.DataFrame, \n",
    "                            cur: sqlite3.Cursor)-> tuple[bool,pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Returns a bool for logic purposes and data to be added into mediums table.\n",
    "    If DB is empty returns original DF. During data update process returns the data not present in the DB\n",
    "    or indicates there is nothing to be added.\n",
    "\n",
    "    :param fields: A list containing field / column names represented as a str\n",
    "    :param table_name: Name of the table into which data is going to be added as a str\n",
    "    :param submedia: Pandas DataFrame containing data to add.\n",
    "    :param cur: A cursor database object\n",
    "    :raise sqlite3.ProgrammingError: If column names don't fit into the table design\n",
    "    :daise sqlite3.OperationalError: If any eceptions on the DB side are raised, i.g. DB being locked\n",
    "    :return: Tuple containing bool for logic purposes and a Pandas DataFrame \n",
    "    as data to be added into the DB during the update\n",
    "    :rtype: tuple[bool, pd.DataFrame]\n",
    "    \"\"\"\n",
    "    \n",
    "    query = (f\"SELECT id, {fields[0]}, {fields[1]}, {fields[2]} FROM {table_name};\")\n",
    "    cur.execute(query)\n",
    "    \n",
    "    in_db = pd.DataFrame(cur.fetchall())\n",
    "    in_db.rename(columns={0: 'id',1: fields[0], 2: fields[1], 3: fields[2]}, inplace=True)\n",
    "    \n",
    "    if len(in_db) == 0:\n",
    "        return (True, submedia)\n",
    "    else:\n",
    "        in_db = list(in_db[fields[0]])\n",
    "        in_df = submedia.copy()\n",
    "        # we check if df contains new data in comparison to DB\n",
    "        new_data = in_df[~in_df.isin(in_db)].dropna()\n",
    "        \n",
    "        if len(new_data) != 0 :\n",
    "            print(f'>>> Adding to {table_name}. New data found.')\n",
    "            return (True, new_data)\n",
    "        print(f'>>> Not adding to {table_name}. No new data found.')\n",
    "        return (False, submedia)\n",
    "\n",
    "def get_id_for_ad_time(fields: list[str], table_: str, \n",
    "                       cur: sqlite3.Cursor)-> tuple[bool,pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Gets IDs from reference tables to ad_time_details table. \n",
    "    Mainly connects time details of singular ad emission with other tables containing details via IDs.\n",
    "    This function populates one of two core tables in this DB.\n",
    "    Returns a bool for logic purposes and data to be added into mediums.\n",
    "\n",
    "    :param fields: A list containing field / column names represented as a str\n",
    "    :param table_: Name of the table out of which the data is going to be pulled, \n",
    "    represented as a str\n",
    "    :param cur: A cursor database object\n",
    "    :raise sqlite3.ProgrammingError: If column names don't fit into the table design\n",
    "    :daise sqlite3.OperationalError: If any eceptions on the DB side are raised, i.g. DB being locked\n",
    "    :return: Tuple containing bool for logic purposes and a Pandas DataFrame \n",
    "    as data to be added into the DB during the update or initial DB fill.\n",
    "    :rtype: tuple[bool, pd.DataFrame]\n",
    "    \"\"\"\n",
    "    \n",
    "    czasy_reklam = df[['Data', 'Godzina bloku reklamowego', 'GG', 'MM', 'dł./mod.', 'Daypart', 'dł. Ujednolicona', 'Detale_kod_reklamy']]\n",
    "    czasy_reklam.index = czasy_reklam.index + get_index_val(table_, cur)\n",
    "\n",
    "    query1 = (\"SELECT dl_ujednolicona, id FROM dl_ujednolicone;\")\n",
    "    cur.execute(query1)\n",
    "    unified_lengths = dict(cur.fetchall())\n",
    "\n",
    "    query2 = (\"SELECT daypart, id FROM dayparty;\")\n",
    "    cur.execute(query2)\n",
    "    dayparts = dict(cur.fetchall())\n",
    "\n",
    "    czasy_reklam.loc[:, 'Daypart'] = czasy_reklam['Daypart'].map(dayparts)\n",
    "    czasy_reklam.loc[:, 'dł. Ujednolicona'] = czasy_reklam['dł. Ujednolicona'].map(unified_lengths)\n",
    "\n",
    "    trigger, czasy_reklam = get_min_max_date(fields, table_, czasy_reklam, cur)\n",
    "    \n",
    "    return (trigger, czasy_reklam)\n",
    "\n",
    "def get_min_max_date(fields: list[str], table_: str, dataframe: pd.DataFrame, \n",
    "                     cur: sqlite3.Cursor)-> tuple[bool, pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Gets max and min dates from selected table. Then checks if dates present in the DF passed as a parameter\n",
    "    are outside of dates range. If so, allows data insertion into the DB, if not it informs the user, \n",
    "    and proceedes with the rest of the code.\n",
    "\n",
    "    :param fields: A list containing field / column names represented as a str\n",
    "    :param table_: Name of the table out of which the data is going to be pulled, \n",
    "    represented as a str\n",
    "    :param dataframe: Pandas DataFrame with the new data to be checked if not present in selected table\n",
    "    :param cur: A cursor database object\n",
    "    :raise sqlite3.ProgrammingError: If column names don't fit into the table design\n",
    "    :daise sqlite3.OperationalError: If any eceptions on the DB side are raised, i.g. DB being locked\n",
    "    :return: Tuple containing bool for logic purposes and a Pandas DataFrame \n",
    "    as data to be added into the DB during the update or initial DB fill.\n",
    "    :rtype: tuple[bool, pd.DataFrame]\n",
    "    \"\"\"\n",
    "    \n",
    "    # Get max date from DB\n",
    "    query = (f\"SELECT MAX({fields[0]}) FROM {table_};\")\n",
    "    cur.execute(query)\n",
    "    in_db_max = pd.Timestamp(cur.fetchone()[0])\n",
    "    \n",
    "    # Get min date from DB\n",
    "    query = (f\"SELECT MIN({fields[0]}) FROM {table_};\")\n",
    "    cur.execute(query)\n",
    "    in_db_min = pd.Timestamp(cur.fetchone()[0])\n",
    "    \n",
    "    # Filter out dates that are already in DB.\n",
    "    filtr = (dataframe['Data'] >= in_db_max) | (dataframe['Data'] <= in_db_min)\n",
    "    dataframe = dataframe.loc[filtr]\n",
    "    \n",
    "    # Get max and min date from DF\n",
    "    in_df_max = dataframe['Data'].max()\n",
    "    in_df_min = dataframe['Data'].min()\n",
    "    \n",
    "    # Check if min and max dates from DF are between range of dates from DB\n",
    "    min_df_in_db_range = in_db_min <= in_df_min <= in_db_max\n",
    "    max_df_in_db_range = in_db_min <= in_df_max <= in_db_max\n",
    "    \n",
    "    # Main logic add if empty or when dates not present in DB.\n",
    "    if  pd.isnull(in_db_max) or pd.isnull(in_db_min) :\n",
    "        return (True, dataframe)\n",
    "    elif not min_df_in_db_range and not max_df_in_db_range:\n",
    "        print(f'>>> Adding to {table_}. New data found.')\n",
    "        return (True, dataframe)\n",
    "    else:\n",
    "        print(f'>>> Not adding to {table_}. One or more dates already in DB.')\n",
    "        print(f'>>> Check the data you want to insert into DB.')\n",
    "        return (False, dataframe)\n",
    "\n",
    "def add_8_fields(data_set:dict[pd.DataFrame,str,list[str]], \n",
    "                 con: sqlite3.Connection, cur: sqlite3.Cursor)-> None:\n",
    "    \"\"\"\n",
    "    Function adding data into ad_time_details table, which consists of 8 columns.\n",
    "\n",
    "    :param data_set: A dict contaning data to be added, table name, and field / column name.\n",
    "    Data is a Pandas DataFrame, table name and field name are both strings.\n",
    "    :raise KeyError: If key name does not match the pattern\n",
    "    :param con: A database connection object\n",
    "    :param cur: A cursor database object\n",
    "    :raise KeyError: If key name does not match the pattern\n",
    "    :raise sqlite3.ProgrammingError: If column names don't fit into the table design\n",
    "    :daise sqlite3.OperationalError: If any eceptions on the DB side are raised, i.g. DB being locked\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    query = (f\"\"\"\n",
    "             INSERT INTO {data_set['table']} (\n",
    "                {data_set['fields'][0]},\n",
    "                {data_set['fields'][1]},\n",
    "                {data_set['fields'][2]},\n",
    "                {data_set['fields'][3]},\n",
    "                {data_set['fields'][4]},\n",
    "                {data_set['fields'][5]},\n",
    "                {data_set['fields'][6]},\n",
    "                {data_set['fields'][7]})\n",
    "            VALUES(\n",
    "                :{data_set['fields'][0]},\n",
    "                :{data_set['fields'][1]},\n",
    "                :{data_set['fields'][2]},\n",
    "                :{data_set['fields'][3]},\n",
    "                :{data_set['fields'][4]},\n",
    "                :{data_set['fields'][5]},\n",
    "                :{data_set['fields'][6]},\n",
    "                :{data_set['fields'][7]})\n",
    "             \"\"\")\n",
    "\n",
    "    for _, elem in data_set['data'].iterrows():\n",
    "        elem.Data = elem.Data.strftime('%Y-%m-%d')\n",
    "        data = {f'{field}': value for field, value in zip(data_set['fields'], elem)}\n",
    "        cur.execute(query, data)\n",
    "        # con.commit()\n",
    "    \n",
    "    con.commit()\n",
    "\n",
    "def add_10_fields(data_set:dict[pd.DataFrame,str,list[str]],\n",
    "                  con: sqlite3.Connection, cur: sqlite3.Cursor)-> None:\n",
    "    \"\"\"\n",
    "    Function adding data into ad_time_details table, which consists of 10 columns.\n",
    "\n",
    "    :param data_set: A dict contaning data to be added, table name, and field / column name.\n",
    "    Data is a Pandas DataFrame, table name and field name are both strings.\n",
    "    :param con: A database connection object\n",
    "    :param cur: A cursor database object\n",
    "    :raise KeyError: If key name does not match the pattern\n",
    "    :raise sqlite3.ProgrammingError: If column names don't fit into the table design\n",
    "    :daise sqlite3.OperationalError: If any eceptions on the DB side are raised, i.g. DB being locked\n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    \n",
    "    query = (f\"\"\"\n",
    "             INSERT INTO {data_set['table']} (\n",
    "                {data_set['fields'][0]},\n",
    "                {data_set['fields'][1]},\n",
    "                {data_set['fields'][2]},\n",
    "                {data_set['fields'][3]},\n",
    "                {data_set['fields'][4]},\n",
    "                {data_set['fields'][5]},\n",
    "                {data_set['fields'][6]},\n",
    "                {data_set['fields'][7]},\n",
    "                {data_set['fields'][8]},\n",
    "                {data_set['fields'][9]})\n",
    "             VALUES(\n",
    "                :{data_set['fields'][0]},\n",
    "                :{data_set['fields'][1]},\n",
    "                :{data_set['fields'][2]},\n",
    "                :{data_set['fields'][3]},\n",
    "                :{data_set['fields'][4]},\n",
    "                :{data_set['fields'][5]},\n",
    "                :{data_set['fields'][6]},\n",
    "                :{data_set['fields'][7]},\n",
    "                :{data_set['fields'][8]},\n",
    "                :{data_set['fields'][9]})\n",
    "             ;\"\"\")\n",
    "\n",
    "    for _, elem in data_set['data'].iterrows():\n",
    "        elem.Data = elem.Data.strftime('%Y-%m-%d')\n",
    "        data = {field: elem for field, elem in zip(data_set['fields'], elem)}\n",
    "        cur.execute(query, data)\n",
    "        \n",
    "    con.commit()\n",
    "    \n",
    "def get_id_for_ads_desc(fields: list[str], table_: str,\n",
    "                        cur: sqlite3.Cursor)-> tuple[bool,pd.DataFrame]:\n",
    "    \"\"\"\n",
    "    Gets IDs from reference tables to ads_desc table. \n",
    "    Mainly connects other tables and data of singular ad emission via IDs with other tables.\n",
    "    This function populates one of two core tables in this DB.\n",
    "    Returns a bool for logic purposes and data to be added into mediums.\n",
    "\n",
    "    :param fields: A list containing field / column names represented as a str\n",
    "    :param table_: Name of the table out of which the data is going to be pulled, \n",
    "    represented as a str\n",
    "    :param cur: A cursor database object\n",
    "    :raise sqlite3.ProgrammingError: If column names don't fit into the table design\n",
    "    :daise sqlite3.OperationalError: If any eceptions on the DB side are raised, i.g. DB being locked\n",
    "    :return: Tuple containing bool for logic purposes and a Pandas DataFrame \n",
    "    as data to be added into the DB during the update or initial DB fill.\n",
    "    :rtype: tuple[bool, pd.DataFrame]\n",
    "    \"\"\"\n",
    "    \n",
    "    spoty = df[['Data', 'Opis Reklamy', 'Kod Reklamy', 'Brand', 'Submedium', 'Detale_kod_reklamy', 'Produkt(4)', 'Koszt [zł]', 'L.emisji', 'Typ reklamy']]\n",
    "    spoty.index = spoty.index + get_index_val(table_, cur)\n",
    "\n",
    "    query1 = (\"SELECT brand, id FROM brandy;\")\n",
    "    cur.execute(query1)\n",
    "    brand_id = dict(cur.fetchall())\n",
    "\n",
    "    query2 =(\"SELECT submedium, id FROM submedia;\")\n",
    "    cur.execute(query2)\n",
    "    submedium_id = dict(cur.fetchall())\n",
    "\n",
    "    query3 = (\"SELECT kod_rek, id FROM czasy_reklam;\")\n",
    "    cur.execute(query3)\n",
    "    czas_reklamy_id = dict(cur.fetchall())\n",
    "\n",
    "    query4 = (\"SELECT typ_produktu, id FROM typy_produktu;\")\n",
    "    cur.execute(query4)\n",
    "    typ_produktu_id = dict(cur.fetchall())\n",
    "\n",
    "    spoty.loc[:, 'Brand'] = spoty['Brand'].map(brand_id)\n",
    "    spoty.loc[:, 'Submedium'] = spoty['Submedium'].map(submedium_id)\n",
    "    spoty.loc[:, 'Detale_kod_reklamy'] = spoty['Detale_kod_reklamy'].map(czas_reklamy_id)\n",
    "    spoty.loc[:, 'Produkt(4)'] = spoty['Produkt(4)'].map(typ_produktu_id)\n",
    "    \n",
    "    trigger, spoty = get_min_max_date(fields, table_, spoty, cur)\n",
    "\n",
    "    return (trigger, spoty)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = sqlite3.Connection('./radio_ads.db')\n",
    "cur = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating DataFrame.\n"
     ]
    }
   ],
   "source": [
    "print('Creating DataFrame.')\n",
    "# Reads the dataframe\n",
    "df = pd.read_csv('../data/live_3.csv', delimiter=';', thousands=',',\n",
    "                 dtype={'Dzień': 'category', 'Dzień tygodnia': 'category', \n",
    "                        'Nr. tyg.': 'category', 'Rok': 'category',\n",
    "                        'Miesiąc': 'category', 'Zasięg medium': 'category',\n",
    "                        'Brand': 'category', 'Produkt(4)': 'category',\n",
    "                        'Kod Reklamy': 'int32', 'Opis Reklamy': 'object',\n",
    "                        'Typ reklamy': 'category', 'Wydawca/Nadawca': 'category',\n",
    "                        'Submedium': 'category', 'dł./mod.': 'int8',\n",
    "                        'GG': 'int8', 'MM': 'int8', 'Koszt [zł]': 'Int32',\n",
    "                        'L.emisji': 'int8', 'dł. Ujednolicona': 'Int8', \n",
    "                        'Godzina bloku reklamowego': 'category'}, \n",
    "                 encoding='utf-8', parse_dates=['Data'], low_memory=False\n",
    "                 )\n",
    "df.sort_values(by='Data', axis=0, inplace=True)\n",
    "df.reset_index(inplace=True)\n",
    "df.drop('index', axis=1, inplace=True)\n",
    "ind = df.index.values + get_index_val('spoty', cur)\n",
    "df2 = df[['Data', 'Kod Reklamy']].copy()\n",
    "df2['Data_str'] = df2['Data'].dt.strftime('%Y-%m-%d')\n",
    "df['Detale_kod_reklamy'] = df2[['Data_str', 'Kod Reklamy']].apply(lambda x: f'{x[\"Data_str\"]} - {x[\"Kod Reklamy\"]} - {ind[x.name]}', axis=1)\n",
    "del df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create datasets for simple tables\n",
    "dow2 = ['Poniedziałek', 'Wtorek', 'Środa', 'Czwartek', 'Piątek',\n",
    "        'Sobota', 'Niedziela']\n",
    "months = [\n",
    "    'Styczeń', 'Luty', 'Marzec', 'Kwiecień', 'Maj',\n",
    "    'Czerwiec', 'Lipiec', 'Sierpień', 'Wrzesień',\n",
    "    'Październik', 'Listopad', 'Grudzień'\n",
    "]\n",
    "dates = df['Data'].dt.strftime('%Y-%m-%d').unique()\n",
    "brands = df['Brand'].sort_values().unique()\n",
    "lengths = ['10', '15', '20', '30', '45', '60',]\n",
    "dayparts = df['Daypart'].unique()\n",
    "product_types = df['Produkt(4)'].sort_values().unique()\n",
    "broadcasters = df['Wydawca/Nadawca'].sort_values().unique()\n",
    "reaches = df['Zasięg medium'].unique()\n",
    "\n",
    "# TODO pomyśleć, czy potrzeba tu odwołania do db i pobrania czegokolwiek. Chyba nie.\n",
    "data_set = [{'data': dow2, 'table': 'dni_tyg', 'field': 'dzien_tyg'},\n",
    "            {'data': months, 'table': 'miesiace', 'field': 'miesiac'},\n",
    "            {'data': dates, 'table': 'data_czas', 'field': 'data'},\n",
    "            {'data': brands, 'table': 'brandy', 'field': 'brand'},\n",
    "            {'data': lengths, 'table': 'dl_ujednolicone', 'field': 'dl_ujednolicona'},\n",
    "            {'data': dayparts, 'table': 'dayparty', 'field': 'daypart'},\n",
    "            {'data': product_types, 'table': 'typy_produktu', 'field': 'typ_produktu'},\n",
    "            {'data': broadcasters, 'table': 'nadawcy', 'field': 'nadawca'},\n",
    "            {'data': reaches, 'table': 'zasiegi', 'field': 'zasieg'},\n",
    "            ]\n",
    "\n",
    "avoid_adding = ['dni_tyg', 'miesiace', 'dl_ujednolicone', 'dayparty', 'zasiegi']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inserting data to one input tables.\n",
      ">>> Not adding to dni_tyg. No new data found.\n",
      ">>> Not adding to miesiace. No new data found.\n",
      ">>> Not adding to data_czas. No new data found.\n",
      ">>> Not adding to brandy. No new data found.\n",
      ">>> Not adding to dl_ujednolicone. No new data found.\n",
      ">>> Not adding to dayparty. No new data found.\n",
      ">>> Not adding to typy_produktu. No new data found.\n",
      ">>> Not adding to nadawcy. No new data found.\n",
      ">>> Not adding to zasiegi. No new data found.\n"
     ]
    }
   ],
   "source": [
    "# Inserting data into simple tables\n",
    "print('Inserting data to one input tables.')\n",
    "try:\n",
    "    iter_over_inputs(data_set, con, cur, avoid_adding)\n",
    "except sqlite3.ProgrammingError as e:\n",
    "    con.close()\n",
    "    print('Failed to input the data.')\n",
    "    print(f'Error: {e}')\n",
    "except sqlite3.OperationalError as e:\n",
    "    con.close()\n",
    "    print('Failed to input the data.')\n",
    "    print(f'Error: {e}')\n",
    "    exit()\n",
    "\n",
    "# Create and insert data into mediums table\n",
    "print('Inserting data to the three input table.')\n",
    "fields = get_column_names('submedia', cur)\n",
    "trigger, submedia = get_id_for_submediums(fields, 'submedia', cur)\n",
    "data_set2 = {'data': submedia, 'table': 'submedia', 'fields': fields}\n",
    "if trigger:\n",
    "    try:\n",
    "        add_3_fields(data_set2, con, cur)\n",
    "    except sqlite3.ProgrammingError as e:\n",
    "        con.close()\n",
    "        print('Failed to input the data.')\n",
    "        print(f'Error: {e}')\n",
    "    except sqlite3.OperationalError as e:\n",
    "        con.close()\n",
    "        print('Failed to input the data.')\n",
    "        print(f'Error: {e}')\n",
    "        exit()\n",
    "\n",
    "# Create and insert data into ad_time_details table\n",
    "print('Inserting data to the eight input table.')\n",
    "fields = get_column_names('czasy_reklam', cur)\n",
    "trigger, czasy_reklam = get_id_for_ad_time(fields, 'czasy_reklam', cur)\n",
    "data_set3 = {'data': czasy_reklam, 'table': 'czasy_reklam', 'fields': fields}\n",
    "if trigger:\n",
    "    try:\n",
    "        add_8_fields(data_set3, con, cur)\n",
    "    except sqlite3.ProgrammingError as e:\n",
    "        con.close()\n",
    "        print('Failed to input the data.')\n",
    "        print(f'Error: {e}')\n",
    "        exit()\n",
    "    except sqlite3.OperationalError as e:\n",
    "        con.close()\n",
    "        print('Failed to input the data.')\n",
    "        print(f'Error: {e}')\n",
    "        exit()\n",
    "\n",
    "# Create and insert data into ad_time_details table\n",
    "print('Inserting data to the ten input table.')\n",
    "fields = get_column_names('spoty', cur)\n",
    "trigger, spoty = get_id_for_ads_desc(fields, 'spoty', cur)\n",
    "data_set4 = {'data': spoty, 'table': 'spoty', 'fields': fields}\n",
    "if trigger:\n",
    "    try:\n",
    "        add_10_fields(data_set4, con, cur)\n",
    "    except sqlite3.ProgrammingError as e:\n",
    "        con.close()\n",
    "        print('Failed to input the data.')\n",
    "        print(f'Error: {e}')\n",
    "        exit()\n",
    "    except sqlite3.OperationalError as e:\n",
    "        con.close()\n",
    "        print('Failed to input the data.')\n",
    "        print(f'Error: {e}')\n",
    "        exit()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
